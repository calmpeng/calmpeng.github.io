# 14｜集群：哪些环节会存在性能瓶颈和数据可靠性风险？

**将把单机的消息队列架构扩展成为分布式的高可靠、高性能的完整集群**

![image-20251223164536629](进阶篇.assets/image-20251223164536629.png)

从技术上看，消息队列的性能和可靠性由 **生产者**、 **Broker** **集群**、 **消费者** 三方共同保障，而不只是服务端的工作。

全链路耗时，即客户端发出一条消息到消费者消费到这条消息的时间差。

![image-20251223164610130](进阶篇.assets/image-20251223164610130.png)

## 生产者的性能和可靠性

![image-20251225154541887](进阶篇.assets/image-20251225154541887.png)

### 网络层面

**连接协议**、 **传输加密**、 **网路稳定性**、 **网络延时**、 **网络带宽**

生产者客户端会先和 Broker **建立并保持 TCP 长连接**，而不是在每次发送数据时都重新连接，以确保通信的性能。

数据传输过程中，为了避免数据包被篡改、窃取，就需要进行**传输加密**。因为网络质量不稳定，传输过程中可能也存在丢包的情况，此时就需要依赖TCP的重传机制来解决问题。

为了保证延时和吞吐，就需要尽量将客户端和服务端部署在同一个可用区内网中，以避免网络链路带来的影响。

 **一般我们会关注客户端节点网卡、中间网络链路、Broker 节点的网卡三个部分的带宽容量。![image-20251225154944314](进阶篇.assets/image-20251225154944314.png)**



### SDK层面

**发送模式**、 **批量语义**、 **异常处理**、 **生产者数量**

#### 发送模式

在生产端，一般支持发送即忘、同步发送、异步发送三种发送模式，发送模式的设计思想是希望在性能和可靠性之间寻找平衡。

**发送即忘** 是指调用 send() 函数后，不用等待服务端的返回结果，因此可以不断地发送数据。这种模式的性能是最高的，可靠性是最低的，因为数据发送失败后没有任何后续的容错处理。

**同步发送** 是指调用 send() 函数后，业务代码同步等待服务端的返回，优点是能保证发送消息的顺序性，这种模式的性能是最低的。其性能高度依赖Broker和服务端之间的网络延时，以及Broker的处理耗时。

**异步发送** 是指调用 send() 函数后，使用异步线程回调的方式发送数据。即在不阻碍主线程的情况下发送数据，此时业务可以一直不停地发送数据。但是如果 send() 速度大于底层发送给Broker的速度，当SDK底层的线程池用完后，发送数据也会阻塞。

总结一下，**从性能上来看，发送即忘 > 异步发送 > 同步发送**。从可靠性来看，**异步发送 = 同步发送 \> 发送即忘**。**同步发送可以保证顺序，异步发送因为重传机制的存在，会无法保证顺序**

#### 批量发送

批量发送是指生产端是否支持 Batch 语义。批量比非批量的吞吐性能高。

从全链路延时来看，因为批量发送需要在生产者客户端本地等待聚合数据，所以**非批量发送的全链路耗时会比批量发送的全链路延时低**。

#### 异常处理

**一般会在数据发送流程中，做好异常捕获、重试的逻辑，并对发送结果进行记录**。比如发送失败的异常信息，发送时候**记录消息的ID或者能唯一标识消息的信息，从而做到发送数据的可追溯。**

#### 生产者数量

最后，因为单个生产者和单个TCP连接是有性能瓶颈的，在业务中我**建议你建立多个生产端实例同时来写入数据，这样可以提高生产者的性能**。



## Broker 的性能和可靠性

**单机和集群两个维度**。单机维度属于**垂直扩容**，集群维度属于**水平扩容**。



### 单机维度

在单机维度，Broker 的性能和可靠性提升可以拆成应用程序、操作系统、物理硬件三个层面。

![image-20251225161332059](进阶篇.assets/image-20251225161332059.png)

### 集群维度

核心思想就是水平扩容，即通过水平扩容添加节点，让集群拥有更强的处理能力。

消息队列集群中，性能和可靠性是通过**创建更多分区、多个副本，并将分区和副本分配到多个节点**上来实现的

![image-20251225161446017](进阶篇.assets/image-20251225161446017.png)

## 消费者的性能和可靠性

客户端SDK和网络。

 **我们主要关注延时和堆积两个指标**

延时是指Broker保存一条消息后，这条消息被客户端消费到的时间差。

堆积是指Broker堆积很多消息没有被及时消费。

消费者的性能和可靠性主要跟 **消费模型**、 **消费重平衡**、 **消费模式**、 **位点提交** 四个方面有关

![image-20251225161627546](进阶篇.assets/image-20251225161627546.png)

### 消费模型

为了提高消息消费的及时性，最好是选择Push模型，即服务端有消息后主动Push给多个客户端，此时的消费的延时是最低的。从提高吞吐来看，为了避免服务端堆积，主流消息队列都是通过客户端主动批量Pull数据来提高吞吐、避免堆积。 **一般情况下，Pull 模型都是默认的消费模型。**

> **核心结论：Pull模型是权衡后的最优解，在保证系统稳定性的前提下，通过技术优化接近Push的实时性。**
>
> **为什么不用Push？三大致命缺陷：**
>
> 1. **慢消费灾难**：消费者处理能力不足时，Push会持续轰炸导致崩溃
> 2. **控制权缺失**：Broker难以适配不同消费者的异构处理能力
> 3. **资源浪费**：Broker需维护复杂的消费者状态，架构沉重
>
> **为什么用Pull？三大核心优势：**
>
> 1. **自主背压**：消费者按自身能力拉取，天然防过载
> 2. **灵活适配**：不同消费者可定制拉取策略（批量大小、频率）
> 3. **架构简洁**：Broker只负责存储，消费者管理偏移量
>
> **技术折中：长轮询（Long Polling）**
>
> - Pull模式通过“阻塞等待新消息”实现**准实时消费**
> - 消费者拉取时，若无新消息则短暂阻塞（如Kafka默认500ms），有消息立即返回
> - **效果**：延迟接近Push，同时保留Pull的所有优势
>
> **一句话总结**：**Pull用“消费者自主控制”换取了系统稳定性，通过长轮询技术弥补了实时性差距，这是分布式系统可靠性的经典设计。**

### 消费分组

消息队列一般是通过消费分组（或订阅）消费数据，以便能自动分配消费关系和保存消费进度。此时当**消费重平衡时，为了重新分配消费关系，所有的消费都会暂停，从而会影响到消费性能**。如果重平衡次数较多，问题就会更加严重。所以，像Flink等流式计算引擎，都会绕过消费分组，指定分区进行消费，以避免重平衡带来的性能下降。而 **RocketMQ 为了解决重平衡问题，就将重平衡移动到了 Broker 端，尽量降低消费重平衡带来的性能影响**。



### 消费模式

在分配消费关系的时候，如果以**分区粒度将分区分配给一个消费**者，此时当**消费者性能有差别时**，就会出现消费倾斜，**导致分区堆积**，从而影响性能

而如果是以消息粒度投递数据，即一个分区的数据能够投递给不同的消费者，此时就不会出现性能问题，性能是更高的，但是**消息数据的顺序性无法保证**。



### 位点提交

从可靠性来看，消费端是不存在丢数据的情况的。但是客户端如果存在错误提交消费位点（Offset）的情况，比如应该提交 Offset 却没有提交，就会导致重复消费；或者不应该提交Offset 却提交了Offset，就会导致消费者没有消费到应该消费的数据，从而导致下游认为数据丢失。此时从代码上来看，建议是手动提交Offset（或ACK），即消费到数据，并且业务逻辑处理成功后，才执行ACK或者提交Offset。



## 小结

![image-20251223164727503](进阶篇.assets/image-20251223164727503.png)

# 15｜集群：如何构建分布式的消息队列集群？（上）

集群的主要功能就是用来提高性能和数据可靠性。从技术上看，设计实现集群化的消息队列主要包含 **节点发现**、 **节点探活**、 **元数据存储**、 **集群管理** 四个方面。

## 有状态服务和无状态服务

我们经常听到有状态服务和无状态服务这两个词。二者之间最重要的一个区别在于： **是否需要在本地存储持久化数据**。需要在本地存储持久化数据的就是有状态服务，反之就是无状态服务。

HTTP Web 服务就是典型的无状态服务。在搭建HTTP Web 集群的时候，我们经常会使用 Nginx 或者在其他网关后面挂一批 HTTP 节点，此时后端的这批 HTTP 服务节点就是一套集群。

![image-20251225165740097](进阶篇.assets/image-20251225165740097.png)

因为HTTP Web是无状态的服务，不同的节点不需要知道其他节点的存在。Nginx 认为后端所有的节点的功能是一样的，所以请求经过Nginx后，**只需要根据一定转发策略，如轮询、加权轮询、按Key Hash等将请求转发给后端的Web 服务节点即可。然后在节点增减的时候，Nginx 会感知到节点的增减，执行转发或者不转发就行了。**

---

**消息队列是有状态服务**。**消息是和分片绑定，分片是和节点绑定**。所以，当需要发送一个消息后，就需要发送到固定的节点，如果把消息发送到错误的节点，就会失败。所以，**为了将消息发送到对的节点和从对的节点削峰数据，消息队列在消息的收发上，就有服务端转发和客户端寻址两种方案**。



## 消息队列的集群设计思路

一般都是基于主从（Master/Slave）思想来设计的。即通过一个组件来管理整个集群的相关工作，比如创建和删除主题、节点上下线等等。这个组件一般叫做**Master（主节点）或Controller（控制器）**。

还需要有一个组件来完成集群元数据（比如节点信息、Topic信息等等）的存储，这个组件一般叫做**元数据服务**。

当然还有一批数据流节点来完成数据的读写和存储工作，这个组件一般叫做 **Broker 或者节点**。



### 元数据存储

![image-20251225165959789](进阶篇.assets/image-20251225165959789.png)

消息队列集群元数据是**指集群中Topic、分区、配置、节点、权限等信息**。元数据必须保证可靠、高效地存储，不允许丢失。因为一旦元数据丢失，其实际的消息数据也会变得没有意义。

业界主要有第三方存储引擎和集群内部自实现存储两种方案。

**依赖第三方存储引擎** 是指直接使用第三方组件来完成元数据信息的存储，比如ZooKeeper、etcd、单机或者分布式数据库等等。这种方案的优点是拿来即用，无需额外的开发成本，产品成型快，稳定性较高。缺点是需要依赖第三方组件，会增加额外的部署维护成本，并且受限于第三方组件的瓶颈和稳定性，也可能会有数据一致性问题。

目前业界主流消息队列都是选用的这个方案，比如 RabbitMQ 基于 Mnesia 或 etcd、Kafka，Pulsar基于ZooKeeper都是用的这个方案。

**集群内部自实现存储** 是指在消息队列应用内部自定义实现元数据存储服务，相当于在消息队列集群中实现一个小型的ZooKeeper。这种方案的优点是集群内部集成了这部分能力，部署架构就很简单轻量，应用自我把控性高，不会有第三方依赖问题。缺点是开发成本高，从头开始自研，相对于成熟组件而言，稳定性上短期会比较弱，需要投入时间打磨。

Kafka 去 ZooKeeper 后的 KRaft 架构中的元数据存储，就是基于这个思路实现的。

### 节点发现

**所有节点知道对方的存在或者有一个组件知道所有节点的存在，这样才能完成后续的集群管理和调度。这个过程就是节点发现的过程**。

从技术上看，当前业界主要有配置文件、类广播机制、集中式组件三种手段来完成节点发现。

1. **配置文件** 是指通过配置文件配置所有节点IP，然后节点启动后根据配置文件去找到所有的节点，从而完成节点发现。
2. **类广播机制** 是指通过广播、DNS解析等机制，自动去发现集群中所有节点。比如通过解析 DNS 域名，得到域名绑定的所有 IP，从而发现集群中所有节点。
3. **集中式组件** 是指所有节点都向集中式组件去注册和删除自身的节点信息，此时这个组件就会包含所有节点的信息，从而完成节点发现。

第一种方案的好处就是实现简单，在节点发现这块几乎不需要额外的开发成本，缺点就是集群扩容需要修改配置文件，水平扩容不方便，需要重启。业界**ZooKeeper和Kafka KRaft就是用的这种方案。**

第二种方案的好处是可以自动发现新节点，自动扩容集群。缺点是开发成本很高，需要通过广播或者类似的机制发现集群中的其他节点。**业界的RabbitMQ和Elasticsearch用的就是这种方案。**

第三种方案的好处是可以动态地感知节点的变更，水平扩容非常方便，实现也简单。所以当前主流消息队列都是用的这种方案。**业界Kafka 基于ZooKeeper的版本，RocketMQ、Pulsar 用的都是这种方案。**



### 节点探活

一般需要有一个角色来对集群内所有节点进行探活或者保活，这个角色一般是主节点（Master/Leader/Controller）或第三方组件。

 **技术上一般分为主动上报和定时探测两种，这两种方式的主要区别在于心跳探活发起方的不同。** 从技术和实现上看，差别都不大，从稳定性来看，一般推荐主动上报。因为由中心组件主动发起探测，**当节点较多时，中心组件可能会有性能瓶颈，所以目前业界主要的探活实现方式也是主动上报**。



![image-20251225171720365](进阶篇.assets/image-20251225171720365.png)

从探测策略上看，基本都是基于ping-pong的方式来完成探活。心跳发起方一般会根据一定的时间间隔发起心跳探测。**如果保活组件一段时间没有接收到心跳或者主动心跳探测失败，就会剔除这个节点。**比如每3秒探测一次，连续3次探测失败就剔除节点。探测行为一般会设置较短的超时时间，以便尽快完成探测。



以Kafka为例，它是**基于 ZooKeeper 提供的临时节点和 Hook 机制来实现节点保活的**。即节点加入集群时会**创建 TCP 长连接并创建临时节点**，当 TCP 连接断开时就会删除临时节点。临时节点的变更会触发后续的相关操作，比如将节点加入集群、将节点剔除集群等等。

所以基于 ZooKeeper 实现节点发现和保活就很简单，只要通过SDK**创建临时节点即可，只要TCP连接存活，临时节点就会存在**。那么怎样确认连接存活呢？底层还是通过ping-pong 机制、客户端主动上报心跳的形式实现的。

因为 ZooKeeper 具备这两个机制且组件相对成熟、稳定性较高，所以很多消息队列都会用 ZooKeeper 来实现节点发现和探活。完成节点探活后，接下来我们来看看集群的主节点是怎么选举出来的。



### 主节点选举

主节点的选择一般有**相互选举和依赖第三方组件争抢注册两种方式**。

**相互选举** 是指所有节点之间相互投票，选出一个得票最多的节点成为Leader。投票的具体实现可以参考Raft算法，这里就不展开。目前业界Zookeeper、Elasticsearch、Kafka KRaft版本等都是用的这种方案。

![image-20251225182411214](进阶篇.assets/image-20251225182411214.png)

**依赖第三方组件争抢注册** 是指通过引入一个集中式组件来辅助完成节点选举。比如可以在ZooKeeper、etcd上的某个位置写入数据，哪个节点先写入成功它就是Leader节点。当节点异常时，会触发其他节点争抢写入数据。以此类推，从而完成主节点的选举。

在消息队列中，这个主节点一般称为 Controller（控制器），Controller 主要是用来**完成集群管理相关的工作，集群的管理操作一般指创建和删除Topic、配置变更等等行为。**

![image-20251225182519835](进阶篇.assets/image-20251225182519835.png)

Metadata Service负责元数据的存储，Controller负责读取、管理元数据信息，并通知集群中的Broker执行各种操作。此时从实际架构实现的角度来看，Broker 的元数据上报可以走路径1，通过 Controller 上报元数据到Metadata Service，也可以直连Metadata Service走路径2上报元数据。



## 集群构建流程拆解

集群启动其实就是节点启动的过程，来看下图：

![image-20251225182906051](进阶篇.assets/image-20251225182906051.png)

节点启动大致分为以下四步：

1. 节点启动时在某个组件（如图中的Controller 或 Metadata Service）上**注册节点数据**，该组件会保存该节点的元数据信息。
2. 节点注册完成后，会触发选举流程**选**举出一个**主**节点（Controller）。
3. 节点会定期向主节点（或Metadata Service）上报**心跳**用来确保异常节点能快速被剔除。
4. 当节点异常下线或有新节点上线时，同步更新集群中的元数据信息。



### 创建Topic

![image-20251225183034501](进阶篇.assets/image-20251225183034501.png)

创建 Topic 大致分为以下四步：

1. 客户端指定分区和副本数量，调用Controller创建Topic。

2. Controller根据当前集群中的节点、节点上的Topic和分区等元数据信息，再根据一定的规则，计算出新的Topic的分区、副本的分布，同时选出分区的Leader（主分片）。

3. Controller调用Metadata Service保存元数据信息。

4. Controller调用各个Broker节点创建Topic、分区、副本。

   

如果要删除Topic，

1. 首先依旧要先往 Controller 发送一个删除Topic的指令；
2. 然后Controller会通知 Topic 分区所在的节点，删除分区和副本数据，删除Topic；
3. 最后再删除Metadata Service中的Topic元数据。

扩容分区的操作也是类似的，Controller接收到扩容分区的指令，根据逻辑计算出新分区所在的节点，然后通知对应的节点创建分区，同时保存相关元数据。





### Leader切换

当新的 Broker 节点加入集群，这个节点就需要在 Controller上进行注册。此时如果节点宕机，因为新节点上没有分区或Topic数据，所以不需要进行 Leader 切换。

而如果已有节点下线，因为节点上有**分区的 Leader 存在，所以需要进行Leader切换**，以便实现服务的高可用。因为集群会监听所有 Broker 的服务状态。当 Broker 挂掉时，Controller就会感知从而触发 Leader 切换操作



![image-20251225183210099](进阶篇.assets/image-20251225183210099.png)

Leader 切换的流程可以分为以下四步：

1. Controller会持续监听节点的存活状态，持续监控Broker节点是否可用。
2. 根据一定的机制，判断节点挂掉后，开始触发执行Leader切换操作。
3. Controller通过RPC调用通知存活的Broker2和Broker3，将对应分区的Follower提升为Leader。
4. 变更保存所有元数据。

从客户端的视角来看，服务端是没有机制通知客户端 Leader 发生切换的。**此时需要依靠客户端主动更新元数据信息来感知已经发生Leader切换。客户端一般会在接收到某些错误码或者定期更新元数据来感知到 Leader 的切换。**

## 小结

集群构建的思路分为有状态服务和无状态服务，两种类型服务的构建思路是不一样的。**有状态服务需要解决元数据存储、节点发现、节点探活、主节点选举等四部分**。

元数据存储主要有依赖第三方组件实现和集群内自定义实现元数据存储两个思路。第三方组件主要有ZooKeeper、etcd等，依赖第三方组件是当前主流的选择，因为其实现较为简单，前期稳定性较高。自定义实现元数据存储是指在消息队列Broker集群内实现元数据存储服务，从而简化架构，实现虽较为复杂，但长期来看相对更合理。

节点发现主要有静态发现和动态发现两个思路。静态发现是指通过配置文件配置好集群的所有节点，各个节点之间通过配置内容来发现对方，从而组建成一个集群。动态发现是指依赖一个中心组件或者类广播机制来动态完成节点之间的相互发现，即当节点上线或下线的时候，及时感知到变化，从而将节点加入到集群或者从集群中剔除。

节点探活主要分为主动上报和定时探测两种，业界主要使用主动上报的实现形式。

**主节点在消息队列中一般叫做Controller**，一般通过节点间选举或者依赖第三方组件争抢注册来完成选举。**Controller 主要用来完成集群内的管理类操作，如节点上下线、Topic创建/删除/修改、Leader切换等等。Controller 由集群中的某个Broker担任。**



# 16｜集群：如何构建分布式的消息队列集群？（下）

在消息队列的集群架构中，元数据存储服务的选型和实现是整个架构设计的核心，其他模块的设计实现都是围绕着元数据存储服务来展开的。

## 元数据存储服务设计选型

### 基于第三方存储引擎

业界主流的分布式消息队列都是选用**分布式的协调服务**，如 ZooKeeper、etcd 等来当集群的元数据存储服务。所以基于第三方存储引擎的集群架构图一般是下面这样子。

![image-20251226111339905](进阶篇.assets/image-20251226111339905.png)

这是一个由单独的元数据存储集群和多台Broker节点组成的消息队列集群。

Broker 连接上Metadata Service 完成节点发现、探活、主节点（Controller）选举等功能。 **其中Controller 的角色是由某一台 Broker 兼任的。**

**Controller 是无状态的，因为它不负责保存数据，只负责计算逻辑**。一般就会让集群中的某台Broker来承担Controller的功能。当这台Broker挂了后，可以依赖元数据存储服务把 Controller 切换到新的 Broker。因为它是无状态的，所以切换是非常快的。

> 多说一句，在这个架构图中，如果你把元数据服务替换成ZooKeeper，这个架构就是Pulsar和Kafka了。如果你把元数据服务换成 NameServer，这个架构就是RocketMQ了。

如果使用这个方案，集群最少得有6个节点，这会导致部署成本、运维复杂度变高。

### 集群内部自实现元数据存储

![image-20251226111651464](进阶篇.assets/image-20251226111651464.png)

**从技术实现来看，主要有三个思路：**

1. 直接在 Broker 内部构建一个小型的元数据存储集群来提供服务。
2. 通过某些可以内嵌到进程的小型的分布式存储服务来完成元数据的存储。
3. 通过某些可以内置的单机持久化的服务，**配合节点间的元数据同步机制来完成元数据的存储**（可能毕竟麻烦，需要而外开发）。

第一种方案需要**在Broker中实现一个元数据集群**。这个元数据集群和Broker集群最大的差别在于**它只需要承担单个集群的元数据管理存储，数据量和规模很小，集群一般不需要扩容**。所以这个集群适合使用“通过配置发现节点的方案”来构建集群。Kafka 的 KRaft 架构用的就是这种方案。

第二种方案是利用某种可以**内嵌到进程的存储服务来存储元数据**，比如**Mnesia**或RocksDB。如果是单机的存储引擎，比如RocksDB，那么主要适用于单机部署的场景。单机存储引擎的方案如果要实现元数据的集群化，那么就得在节点之间实现相互同步数据的机制，这个就相对复杂许多。**而如果是分布式的存储引擎，如Mnesia，那么就简单许多，几乎没有工作量，直接调用存储引擎的接口存储元数据即可。**（RabbitMQ）

第三种方案是在**节点上部署一个持久化的单机存储引擎，如RocksDB等**。然后在Broker内维护节点间的元数据数据的一致性。这种方式也是一种实现比较简单的方案，开发难度低于第一种方案，高于第二种方案。

从业界实现来看，目前第一种和第二种方案都有在使用。**第三种方案主要用在单机模式下，问题是要维护多个节点的存储服务之间的数据一致性，有一定的开发工作量，并且保持数据强一致比较难。**

在集群中实现元数据服务的优点是，后期架构会很简洁，不需要依赖第三方组件。缺点是需要自研实现，研发投入高。而如果使用独立的元数据服务，因为是现成的组件，产品成型就会很快，这也是当前主流消息队列都是依赖第三方组件来实现元数据存储的原因。所以当前主流消息队列的架构如下所示



### ZooKeeper的集群构建

ZooKeeper 是一个分布式的数据协调服务，本质上是一个简单的、分布式、可靠的数据存储服务。

核心操作就是数据的写入、分发、读取和 Hook。从客户端看，主要操作就是写入和读取。从服务端看，主要操作就是集群构建、数据接收、存储、分发和 Hook。

在集群构建上，它会事先在配置中定义好集群中所有节点的IP列表。然后集群启动时，会在这些节点之间进行选举，经过多数投票机制，选举出一个Leader节点，从而构建成为集群。在单节点上，集群构建相关的配置一般如下所示，配置中会包含所有节点信息。

```java
server.0=10.0.32.1:2888:3888
server.1=10.0.32.2:2888:3888
server.2=10.0.32.3:2888:3888
```

在节点启动的时候，节点之间就会两两进行通信，触发投票。然后根据票数的多少，基于多数原则，选择出一个Leader出来。当 Leader 节点发生宕机或者增加节点时，就会重新触发选举。

![image-20251226142212676](进阶篇.assets/image-20251226142212676.png)

多数投票是一个经常用到的投票机制，即某个节点获得票数超过可投票的节点的一半后，就可以当选为Leader。 **从实现角度，一般是通过集群中节点之间的通信和间隔随机投票的机制来完成投票，以保证能够在短时间内完成选举。**

当选举完成后，Leader 会主动给各个Follower节点发送ping-pong请求，以确定节点是否还活着。当Follower心跳异常时，就会剔除该节点，当集群中可用的节点数少于总节点数的一半，就会选举不出Leader，从而导致集群异常。

**因为ZooKeeper只是一个数据存储服务**，并没有很多管控操作，**Leader节点就负责数据的写入和分发**，**Follower 不负责写入，只负责数据的读取**。当Leader收到操作请求时，比如创建节点、删除节点、修改内容、修改权限等等，会保存数据并分发到多个Follower，**当集群中有一半的Follower返回成功后，数据就保存成功了**。当Follower收到写入请求时，就把写入请求转发给Leader节点进行处理。

因为功能和定位上的差异，**ZooKeeper上是没有Controller和元数据存储的概念的**。它是比较典型的**基于固定配置构建集群的方式。**



### Kafka的集群构建

Kafka 基于 ZooKeeper 和基于 KRaft 构建集群的两种实现方式。

#### 基于ZooKeeper的集群

Kafka 将 ZooKeeper 作为节点发现和元数据存储的组件，通过在 ZooKeeper 上创建临时节点来完成节点发现，并在不同的节点上保存各种元数据信息。

![image-20251226143247878](进阶篇.assets/image-20251226143247878-17667307717441.png)

Broker 在启动或重连时，会根据配置中的 ZooKeeper 地址**找到集群对应的ZooKeeper 集群**。然后会在 ZooKeeper 的 /broker/ids 目录中创建名称为**自身BrokerID的临时节点**，**同时在节点中保存自身的 Broker IP 和 ID 等信息**。当 Broker 宕机或异常时，TCP连接就会断开或者超时，此时临时节点就会被删除。如下两张图，分别是 /broker/ids 节点下的结构和BrokerID中的内容。



![image-20251226143400511](进阶篇.assets/image-20251226143409957.png)

节点之间的探活依赖 ZooKeeper 内置的探活机制。

在Kafka中，**Controller是一个虚拟概念，是运行在某台Broker上的一段代码逻辑**。集群中需要确认一台Broker 承担 Controller的角色，那 Controller 是怎么选出来的呢？我们来看一看。

Kafka 的 Controller 选举机制非常简单，**即在 ZooKeeper 上固定有一个节点 /controller。每台Broker启动的时候都会去 ZooKeeper 判断一下这个节点是否存在。如果存在就认为已经有Controller了，如果没有，就把自己的信息注册上去，自己来当Controller。**集群每个Broker 都会监听/Controller 节点，当监听到节点不存在时，都会主动去尝试创建节点，注册自己的信息。 **哪台节点注册成功，这个节点就是新的** **Controller。**

Controller 会监听 ZooKeeper 上多个不同目录，主要监听目录中子节点的增加、删除，节点内容变更等行为。

Kafka 集群中每台 Broker 中都有集群全量的元数据信息，每台节点的元数据信息大部分是通过Controller 来维护的，比如Topic、分区、副本。然后根据不同的Hook（如创建、删除Topic等），**将这些元数据通过TCP调用的形式通知给集群中其他的节点，以保持集群中所有节点元数据信息是最新的。**

![image-20251226143643205](进阶篇.assets/image-20251226143643205.png)

Kafka 创建Topic有两种形式（图中1和2），即通过 Broker 来创建和通过 ZooKeeper来创建。**当调用 Broker 创建Topic时**，Broker 会根据本地的全量元数据信息，算出新Topic的分区、副本分布，**然后将这些数据写入到 ZooKeeper**。然后 **Controller 就会Hook到创建Topic的行为，更新本地缓存元数据信息，通知对应的Broker节点创建分区和副本**。 所以，**也可以通过直接生成计划然后、写入到ZooKeeper的方式来创建Topic**。

#### 基于KRaft的集群

从架构的角度，基于KRaft 实现的Kafka集群做的事情就是将集群的元数据存储服务从 ZooKeeper 替换成为内部实现的 Metadata 模块。这个模块会同时完成 Controller 和元数据存储的工作

![image-20251226143755234](进阶篇.assets/image-20251226143755234.png)

我们前面讲过， **集群元数据需要分布式存储才能保证数据的高可靠**。所以 Kafka KRaft 架构的 Metadata 模块是基于 Raft 协议实现的 KRaft，从而实现元数据可靠存储的。

因为 Kafka的 Metadata 模块只需要完成元数据存储，所以它的设计思路和 ZooKeeper 是一样的，是主从架构。即通过在配置文件中配置节点列表，然后通过投票来选举出Leader节点。这个节点会承担集群管控、元数据存储和分发等功能。

Metadata 模块的配置如下所示。即通过配置项 controoler.quorum.votes 配置允许成为 Controller 的节点列表，然后这些节点之间会通过投票选举出Leader节点，这个Leader会完成Controller和元数据存储的工作。这个Leader相当于基于 ZooKeeper 版本中的Controller和ZooKeeper的Leader。

在这个版本架构的实现中，就只有Controller了，然后 Controller 自带了元数据存储的功能。所以架构上就会变成了下面这个样子。

![image-20251226152357142](进阶篇.assets/image-20251226152357142.png)

Broker 之间通过投票选举出来的Leader节点就是Controller。此时所有 Broker 都会和 Controller 保持通信，以维护节点的在线状态，从而完成节点发现。当 Controller 发现Broker增加或异常时，就会主动执行后续的操作。

从链路来看，这个架构简化了通过监听 ZooKeeper 来发现节点变更的流程，链路更短，稳定性更高。和基于 ZooKeeper 的架构一样，每台 Broker 依旧有集群全量的元数据信息，这些元数据信息的维护也是通过Controller完成的。

![image-20251226152517399](进阶篇.assets/image-20251226152517399.png)

因为没有 ZooKeeper，所以创建 Topic 只有通过Broker创建的方式。通过 Admin SDK 调用Broker创建Topic，如果 Broker 不是 Controller，**这个请求就会转发到当前的Controller上。Controller 会根据本地的元数据信息生成新Topic的分区、副本的分布，然后调用对应的Broker节点完成分区和副本数据的创建，最后会保存元数据**。

你会发现基于KRaft的Kafka架构比基于ZooKeeper架构简单清晰非常多，操作链路也短很多。这样可以解决基于 ZooKeeper 架构中一些难以解决的问题，如集群可承载分区数量上限较低、缓存不一致等等

## 小结

消息队列的**主流实现方式都是依赖第三方组件来完成数据存储**，常见的有ZooKeeper、etcd等。为了简化架构，我们还可以通过在集群内自建元数据存储服务来替代第三方组件，虽然需要研发投入，但从架构长期演进的合理性来看，我是推荐这种方式的，毕竟后期架构会很简洁。

ZooKeeper 集群的组件，**是基于配置文件中指定集群中其他节点的IP地址和端口来实现节点发现的，属于单播发现机制。这种方式的缺点就是扩容需要修改配置、重启集群**（ZooKeeper 3.5.0及以上版 支持动态配置）。所以，还有一种通过**配置多播地址和端口来实现集群发现的方式**，其好处是可以动态发现节点，属于单播的一种升级，目前Elasticsearch和消息队列RabbitMQ都属于多播的实现。

> 正是由于多播在云环境中的局限性，现代分布式系统（包括新版 Elasticsearch、RabbitMQ 以及 Kafka、Pinpoint 等）越来越多地采用一种结合了**静态配置的便利性和动态发现的弹性**的架构：**基于外部协调服务（如 ZooKeeper、Consul、Etcd）的发现机制**。
>
> 这种模式下，系统集群的节点信息被注册到 ZooKeeper 等协调服务中。新节点启动时，通过预先配置的少数几个协调服务地址（类似“引路人”），从协调中心获取完整的集群视图。这种方式既避免了多播的网络限制，又实现了动态发现，成为了当前复杂网络环境下更可靠的选择

从Kafka的集群构建来看，基于独立的元数据存储服务，会导致架构复杂和引入缓存不一致等问题。集群内部实现元数据存储，可以简化架构，避免不一致。从技术合理性来看，我更建议你使用内置元数据存储的方案。































