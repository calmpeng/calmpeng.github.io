# 14｜集群：哪些环节会存在性能瓶颈和数据可靠性风险？

**将把单机的消息队列架构扩展成为分布式的高可靠、高性能的完整集群**

![image-20251223164536629](进阶篇.assets/image-20251223164536629.png)

从技术上看，消息队列的性能和可靠性由 **生产者**、 **Broker** **集群**、 **消费者** 三方共同保障，而不只是服务端的工作。

全链路耗时，即客户端发出一条消息到消费者消费到这条消息的时间差。

![image-20251223164610130](进阶篇.assets/image-20251223164610130.png)

## 生产者的性能和可靠性

![image-20251225154541887](进阶篇.assets/image-20251225154541887.png)

### 网络层面

**连接协议**、 **传输加密**、 **网路稳定性**、 **网络延时**、 **网络带宽**

生产者客户端会先和 Broker **建立并保持 TCP 长连接**，而不是在每次发送数据时都重新连接，以确保通信的性能。

数据传输过程中，为了避免数据包被篡改、窃取，就需要进行**传输加密**。因为网络质量不稳定，传输过程中可能也存在丢包的情况，此时就需要依赖TCP的重传机制来解决问题。

为了保证延时和吞吐，就需要尽量将客户端和服务端部署在同一个可用区内网中，以避免网络链路带来的影响。

 **一般我们会关注客户端节点网卡、中间网络链路、Broker 节点的网卡三个部分的带宽容量。![image-20251225154944314](进阶篇.assets/image-20251225154944314.png)**



### SDK层面

**发送模式**、 **批量语义**、 **异常处理**、 **生产者数量**

#### 发送模式

在生产端，一般支持发送即忘、同步发送、异步发送三种发送模式，发送模式的设计思想是希望在性能和可靠性之间寻找平衡。

**发送即忘** 是指调用 send() 函数后，不用等待服务端的返回结果，因此可以不断地发送数据。这种模式的性能是最高的，可靠性是最低的，因为数据发送失败后没有任何后续的容错处理。

**同步发送** 是指调用 send() 函数后，业务代码同步等待服务端的返回，优点是能保证发送消息的顺序性，这种模式的性能是最低的。其性能高度依赖Broker和服务端之间的网络延时，以及Broker的处理耗时。

**异步发送** 是指调用 send() 函数后，使用异步线程回调的方式发送数据。即在不阻碍主线程的情况下发送数据，此时业务可以一直不停地发送数据。但是如果 send() 速度大于底层发送给Broker的速度，当SDK底层的线程池用完后，发送数据也会阻塞。

总结一下，**从性能上来看，发送即忘 > 异步发送 > 同步发送**。从可靠性来看，**异步发送 = 同步发送 \> 发送即忘**。**同步发送可以保证顺序，异步发送因为重传机制的存在，会无法保证顺序**

#### 批量发送

批量发送是指生产端是否支持 Batch 语义。批量比非批量的吞吐性能高。

从全链路延时来看，因为批量发送需要在生产者客户端本地等待聚合数据，所以**非批量发送的全链路耗时会比批量发送的全链路延时低**。

#### 异常处理

**一般会在数据发送流程中，做好异常捕获、重试的逻辑，并对发送结果进行记录**。比如发送失败的异常信息，发送时候**记录消息的ID或者能唯一标识消息的信息，从而做到发送数据的可追溯。**

#### 生产者数量

最后，因为单个生产者和单个TCP连接是有性能瓶颈的，在业务中我**建议你建立多个生产端实例同时来写入数据，这样可以提高生产者的性能**。



## Broker 的性能和可靠性

**单机和集群两个维度**。单机维度属于**垂直扩容**，集群维度属于**水平扩容**。



### 单机维度

在单机维度，Broker 的性能和可靠性提升可以拆成应用程序、操作系统、物理硬件三个层面。

![image-20251225161332059](进阶篇.assets/image-20251225161332059.png)

### 集群维度

核心思想就是水平扩容，即通过水平扩容添加节点，让集群拥有更强的处理能力。

消息队列集群中，性能和可靠性是通过**创建更多分区、多个副本，并将分区和副本分配到多个节点**上来实现的

![image-20251225161446017](进阶篇.assets/image-20251225161446017.png)

## 消费者的性能和可靠性

客户端SDK和网络。

 **我们主要关注延时和堆积两个指标**

延时是指Broker保存一条消息后，这条消息被客户端消费到的时间差。

堆积是指Broker堆积很多消息没有被及时消费。

消费者的性能和可靠性主要跟 **消费模型**、 **消费重平衡**、 **消费模式**、 **位点提交** 四个方面有关

![image-20251225161627546](进阶篇.assets/image-20251225161627546.png)

### 消费模型

为了提高消息消费的及时性，最好是选择Push模型，即服务端有消息后主动Push给多个客户端，此时的消费的延时是最低的。从提高吞吐来看，为了避免服务端堆积，主流消息队列都是通过客户端主动批量Pull数据来提高吞吐、避免堆积。 **一般情况下，Pull 模型都是默认的消费模型。**

> **核心结论：Pull模型是权衡后的最优解，在保证系统稳定性的前提下，通过技术优化接近Push的实时性。**
>
> **为什么不用Push？三大致命缺陷：**
>
> 1. **慢消费灾难**：消费者处理能力不足时，Push会持续轰炸导致崩溃
> 2. **控制权缺失**：Broker难以适配不同消费者的异构处理能力
> 3. **资源浪费**：Broker需维护复杂的消费者状态，架构沉重
>
> **为什么用Pull？三大核心优势：**
>
> 1. **自主背压**：消费者按自身能力拉取，天然防过载
> 2. **灵活适配**：不同消费者可定制拉取策略（批量大小、频率）
> 3. **架构简洁**：Broker只负责存储，消费者管理偏移量
>
> **技术折中：长轮询（Long Polling）**
>
> - Pull模式通过“阻塞等待新消息”实现**准实时消费**
> - 消费者拉取时，若无新消息则短暂阻塞（如Kafka默认500ms），有消息立即返回
> - **效果**：延迟接近Push，同时保留Pull的所有优势
>
> **一句话总结**：**Pull用“消费者自主控制”换取了系统稳定性，通过长轮询技术弥补了实时性差距，这是分布式系统可靠性的经典设计。**

### 消费分组

消息队列一般是通过消费分组（或订阅）消费数据，以便能自动分配消费关系和保存消费进度。此时当**消费重平衡时，为了重新分配消费关系，所有的消费都会暂停，从而会影响到消费性能**。如果重平衡次数较多，问题就会更加严重。所以，像Flink等流式计算引擎，都会绕过消费分组，指定分区进行消费，以避免重平衡带来的性能下降。而 **RocketMQ 为了解决重平衡问题，就将重平衡移动到了 Broker 端，尽量降低消费重平衡带来的性能影响**。



### 消费模式

在分配消费关系的时候，如果以**分区粒度将分区分配给一个消费**者，此时当**消费者性能有差别时**，就会出现消费倾斜，**导致分区堆积**，从而影响性能

而如果是以消息粒度投递数据，即一个分区的数据能够投递给不同的消费者，此时就不会出现性能问题，性能是更高的，但是**消息数据的顺序性无法保证**。



### 位点提交

从可靠性来看，消费端是不存在丢数据的情况的。但是客户端如果存在错误提交消费位点（Offset）的情况，比如应该提交 Offset 却没有提交，就会导致重复消费；或者不应该提交Offset 却提交了Offset，就会导致消费者没有消费到应该消费的数据，从而导致下游认为数据丢失。此时从代码上来看，建议是手动提交Offset（或ACK），即消费到数据，并且业务逻辑处理成功后，才执行ACK或者提交Offset。



## 小结

![image-20251223164727503](进阶篇.assets/image-20251223164727503.png)

# 15｜集群：如何构建分布式的消息队列集群？（上）

集群的主要功能就是用来提高性能和数据可靠性。从技术上看，设计实现集群化的消息队列主要包含 **节点发现**、 **节点探活**、 **元数据存储**、 **集群管理** 四个方面。

## 有状态服务和无状态服务

我们经常听到有状态服务和无状态服务这两个词。二者之间最重要的一个区别在于： **是否需要在本地存储持久化数据**。需要在本地存储持久化数据的就是有状态服务，反之就是无状态服务。

HTTP Web 服务就是典型的无状态服务。在搭建HTTP Web 集群的时候，我们经常会使用 Nginx 或者在其他网关后面挂一批 HTTP 节点，此时后端的这批 HTTP 服务节点就是一套集群。

![image-20251225165740097](进阶篇.assets/image-20251225165740097.png)

因为HTTP Web是无状态的服务，不同的节点不需要知道其他节点的存在。Nginx 认为后端所有的节点的功能是一样的，所以请求经过Nginx后，**只需要根据一定转发策略，如轮询、加权轮询、按Key Hash等将请求转发给后端的Web 服务节点即可。然后在节点增减的时候，Nginx 会感知到节点的增减，执行转发或者不转发就行了。**

---

**消息队列是有状态服务**。**消息是和分片绑定，分片是和节点绑定**。所以，当需要发送一个消息后，就需要发送到固定的节点，如果把消息发送到错误的节点，就会失败。所以，**为了将消息发送到对的节点和从对的节点削峰数据，消息队列在消息的收发上，就有服务端转发和客户端寻址两种方案**。



## 消息队列的集群设计思路

一般都是基于主从（Master/Slave）思想来设计的。即通过一个组件来管理整个集群的相关工作，比如创建和删除主题、节点上下线等等。这个组件一般叫做**Master（主节点）或Controller（控制器）**。

还需要有一个组件来完成集群元数据（比如节点信息、Topic信息等等）的存储，这个组件一般叫做**元数据服务**。

当然还有一批数据流节点来完成数据的读写和存储工作，这个组件一般叫做 **Broker 或者节点**。



### 元数据存储

![image-20251225165959789](进阶篇.assets/image-20251225165959789.png)

消息队列集群元数据是**指集群中Topic、分区、配置、节点、权限等信息**。元数据必须保证可靠、高效地存储，不允许丢失。因为一旦元数据丢失，其实际的消息数据也会变得没有意义。

业界主要有第三方存储引擎和集群内部自实现存储两种方案。

**依赖第三方存储引擎** 是指直接使用第三方组件来完成元数据信息的存储，比如ZooKeeper、etcd、单机或者分布式数据库等等。这种方案的优点是拿来即用，无需额外的开发成本，产品成型快，稳定性较高。缺点是需要依赖第三方组件，会增加额外的部署维护成本，并且受限于第三方组件的瓶颈和稳定性，也可能会有数据一致性问题。

目前业界主流消息队列都是选用的这个方案，比如 RabbitMQ 基于 Mnesia 或 etcd、Kafka，Pulsar基于ZooKeeper都是用的这个方案。

**集群内部自实现存储** 是指在消息队列应用内部自定义实现元数据存储服务，相当于在消息队列集群中实现一个小型的ZooKeeper。这种方案的优点是集群内部集成了这部分能力，部署架构就很简单轻量，应用自我把控性高，不会有第三方依赖问题。缺点是开发成本高，从头开始自研，相对于成熟组件而言，稳定性上短期会比较弱，需要投入时间打磨。

Kafka 去 ZooKeeper 后的 KRaft 架构中的元数据存储，就是基于这个思路实现的。

### 节点发现

**所有节点知道对方的存在或者有一个组件知道所有节点的存在，这样才能完成后续的集群管理和调度。这个过程就是节点发现的过程**。

从技术上看，当前业界主要有配置文件、类广播机制、集中式组件三种手段来完成节点发现。

1. **配置文件** 是指通过配置文件配置所有节点IP，然后节点启动后根据配置文件去找到所有的节点，从而完成节点发现。
2. **类广播机制** 是指通过广播、DNS解析等机制，自动去发现集群中所有节点。比如通过解析 DNS 域名，得到域名绑定的所有 IP，从而发现集群中所有节点。
3. **集中式组件** 是指所有节点都向集中式组件去注册和删除自身的节点信息，此时这个组件就会包含所有节点的信息，从而完成节点发现。

第一种方案的好处就是实现简单，在节点发现这块几乎不需要额外的开发成本，缺点就是集群扩容需要修改配置文件，水平扩容不方便，需要重启。业界**ZooKeeper和Kafka KRaft就是用的这种方案。**

第二种方案的好处是可以自动发现新节点，自动扩容集群。缺点是开发成本很高，需要通过广播或者类似的机制发现集群中的其他节点。**业界的RabbitMQ和Elasticsearch用的就是这种方案。**

第三种方案的好处是可以动态地感知节点的变更，水平扩容非常方便，实现也简单。所以当前主流消息队列都是用的这种方案。**业界Kafka 基于ZooKeeper的版本，RocketMQ、Pulsar 用的都是这种方案。**



### 节点探活

一般需要有一个角色来对集群内所有节点进行探活或者保活，这个角色一般是主节点（Master/Leader/Controller）或第三方组件。

 **技术上一般分为主动上报和定时探测两种，这两种方式的主要区别在于心跳探活发起方的不同。** 从技术和实现上看，差别都不大，从稳定性来看，一般推荐主动上报。因为由中心组件主动发起探测，**当节点较多时，中心组件可能会有性能瓶颈，所以目前业界主要的探活实现方式也是主动上报**。



![image-20251225171720365](进阶篇.assets/image-20251225171720365.png)

从探测策略上看，基本都是基于ping-pong的方式来完成探活。心跳发起方一般会根据一定的时间间隔发起心跳探测。**如果保活组件一段时间没有接收到心跳或者主动心跳探测失败，就会剔除这个节点。**比如每3秒探测一次，连续3次探测失败就剔除节点。探测行为一般会设置较短的超时时间，以便尽快完成探测。



以Kafka为例，它是**基于 ZooKeeper 提供的临时节点和 Hook 机制来实现节点保活的**。即节点加入集群时会**创建 TCP 长连接并创建临时节点**，当 TCP 连接断开时就会删除临时节点。临时节点的变更会触发后续的相关操作，比如将节点加入集群、将节点剔除集群等等。

所以基于 ZooKeeper 实现节点发现和保活就很简单，只要通过SDK**创建临时节点即可，只要TCP连接存活，临时节点就会存在**。那么怎样确认连接存活呢？底层还是通过ping-pong 机制、客户端主动上报心跳的形式实现的。

因为 ZooKeeper 具备这两个机制且组件相对成熟、稳定性较高，所以很多消息队列都会用 ZooKeeper 来实现节点发现和探活。完成节点探活后，接下来我们来看看集群的主节点是怎么选举出来的。



### 主节点选举

主节点的选择一般有**相互选举和依赖第三方组件争抢注册两种方式**。

**相互选举** 是指所有节点之间相互投票，选出一个得票最多的节点成为Leader。投票的具体实现可以参考Raft算法，这里就不展开。目前业界Zookeeper、Elasticsearch、Kafka KRaft版本等都是用的这种方案。

![image-20251225182411214](进阶篇.assets/image-20251225182411214.png)

**依赖第三方组件争抢注册** 是指通过引入一个集中式组件来辅助完成节点选举。比如可以在ZooKeeper、etcd上的某个位置写入数据，哪个节点先写入成功它就是Leader节点。当节点异常时，会触发其他节点争抢写入数据。以此类推，从而完成主节点的选举。

在消息队列中，这个主节点一般称为 Controller（控制器），Controller 主要是用来**完成集群管理相关的工作，集群的管理操作一般指创建和删除Topic、配置变更等等行为。**

![image-20251225182519835](进阶篇.assets/image-20251225182519835.png)

Metadata Service负责元数据的存储，Controller负责读取、管理元数据信息，并通知集群中的Broker执行各种操作。此时从实际架构实现的角度来看，Broker 的元数据上报可以走路径1，通过 Controller 上报元数据到Metadata Service，也可以直连Metadata Service走路径2上报元数据。



## 集群构建流程拆解

集群启动其实就是节点启动的过程，来看下图：

![image-20251225182906051](进阶篇.assets/image-20251225182906051.png)

节点启动大致分为以下四步：

1. 节点启动时在某个组件（如图中的Controller 或 Metadata Service）上**注册节点数据**，该组件会保存该节点的元数据信息。
2. 节点注册完成后，会触发选举流程**选**举出一个**主**节点（Controller）。
3. 节点会定期向主节点（或Metadata Service）上报**心跳**用来确保异常节点能快速被剔除。
4. 当节点异常下线或有新节点上线时，同步更新集群中的元数据信息。



### 创建Topic

![image-20251225183034501](进阶篇.assets/image-20251225183034501.png)

创建 Topic 大致分为以下四步：

1. 客户端指定分区和副本数量，调用Controller创建Topic。

2. Controller根据当前集群中的节点、节点上的Topic和分区等元数据信息，再根据一定的规则，计算出新的Topic的分区、副本的分布，同时选出分区的Leader（主分片）。

3. Controller调用Metadata Service保存元数据信息。

4. Controller调用各个Broker节点创建Topic、分区、副本。

   

如果要删除Topic，

1. 首先依旧要先往 Controller 发送一个删除Topic的指令；
2. 然后Controller会通知 Topic 分区所在的节点，删除分区和副本数据，删除Topic；
3. 最后再删除Metadata Service中的Topic元数据。

扩容分区的操作也是类似的，Controller接收到扩容分区的指令，根据逻辑计算出新分区所在的节点，然后通知对应的节点创建分区，同时保存相关元数据。





### Leader切换

当新的 Broker 节点加入集群，这个节点就需要在 Controller上进行注册。此时如果节点宕机，因为新节点上没有分区或Topic数据，所以不需要进行 Leader 切换。

而如果已有节点下线，因为节点上有**分区的 Leader 存在，所以需要进行Leader切换**，以便实现服务的高可用。因为集群会监听所有 Broker 的服务状态。当 Broker 挂掉时，Controller就会感知从而触发 Leader 切换操作



![image-20251225183210099](进阶篇.assets/image-20251225183210099.png)

Leader 切换的流程可以分为以下四步：

1. Controller会持续监听节点的存活状态，持续监控Broker节点是否可用。
2. 根据一定的机制，判断节点挂掉后，开始触发执行Leader切换操作。
3. Controller通过RPC调用通知存活的Broker2和Broker3，将对应分区的Follower提升为Leader。
4. 变更保存所有元数据。

从客户端的视角来看，服务端是没有机制通知客户端 Leader 发生切换的。**此时需要依靠客户端主动更新元数据信息来感知已经发生Leader切换。客户端一般会在接收到某些错误码或者定期更新元数据来感知到 Leader 的切换。**

## 小结

集群构建的思路分为有状态服务和无状态服务，两种类型服务的构建思路是不一样的。**有状态服务需要解决元数据存储、节点发现、节点探活、主节点选举等四部分**。

元数据存储主要有依赖第三方组件实现和集群内自定义实现元数据存储两个思路。第三方组件主要有ZooKeeper、etcd等，依赖第三方组件是当前主流的选择，因为其实现较为简单，前期稳定性较高。自定义实现元数据存储是指在消息队列Broker集群内实现元数据存储服务，从而简化架构，实现虽较为复杂，但长期来看相对更合理。

节点发现主要有静态发现和动态发现两个思路。静态发现是指通过配置文件配置好集群的所有节点，各个节点之间通过配置内容来发现对方，从而组建成一个集群。动态发现是指依赖一个中心组件或者类广播机制来动态完成节点之间的相互发现，即当节点上线或下线的时候，及时感知到变化，从而将节点加入到集群或者从集群中剔除。

节点探活主要分为主动上报和定时探测两种，业界主要使用主动上报的实现形式。

**主节点在消息队列中一般叫做Controller**，一般通过节点间选举或者依赖第三方组件争抢注册来完成选举。**Controller 主要用来完成集群内的管理类操作，如节点上下线、Topic创建/删除/修改、Leader切换等等。Controller 由集群中的某个Broker担任。**





